{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbce91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.616161Z",
     "start_time": "2022-05-13T00:32:35.821479Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9ecf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.631674Z",
     "start_time": "2022-05-13T00:32:36.617162Z"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_labels = [\n",
    "    'headset',          # 0\n",
    "    'headset fwd',      # 1\n",
    "    'left controller',  # 2\n",
    "    'right controller', # 3\n",
    "    'head',             # 4\n",
    "    'neck',             # 5\n",
    "    'left shoulder',    # 6\n",
    "    'right shoulder',   # 7\n",
    "    'left elbow',       # 8\n",
    "    'right elbow',      # 9\n",
    "    'left hip',         # 10\n",
    "    'right hip',        # 11\n",
    "    'left knee',        # 12\n",
    "    'right knee',       # 13\n",
    "    'left foot',        # 14\n",
    "    'right foot',       # 15\n",
    "    'left toes',        # 16\n",
    "    'right toes',       # 17\n",
    "    'scale'             # 18\n",
    "]\n",
    "\n",
    "IMG_SIZE = 256 # size of images on disk\n",
    "all_datasets = os.path.join(os.getcwd(), os.pardir, 'datasets')\n",
    "\n",
    "datasets = os.listdir(all_datasets)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5818269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.647188Z",
     "start_time": "2022-05-13T00:32:36.632675Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_dataset = datasets[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4499d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(loc):\n",
    "    data = os.listdir(loc)\n",
    "    capdata_loc = os.path.join(loc, [x for x in data if \"Dataset\" in x][0])\n",
    "    captures = [os.path.join(capdata_loc, x) for x in os.listdir(capdata_loc) if \"captures\" in x]\n",
    "    # rgb_loc = os.path.join(loc, [x for x in data if \"RGB\" in x][0])\n",
    "    # rgbs = [os.path.join(rgb_loc, x) for x in os.listdir(rgb_loc)]\n",
    "    # semseg_loc = [x for x in data if \"Semantic\" in x][0]\n",
    "    # semseg = [os.path.join(semseg_loc, x) for x in os.listdir(os.path.join(loc,semseg_loc))]\n",
    "    return captures #, rgbs, semseg\n",
    "\n",
    "# https://stackoverflow.com/questions/48265646/rotation-of-a-vector-python\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.\"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Finds angle between two vectors\"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def x_rotation(vector,theta):\n",
    "    \"\"\"Rotates 3-D vector around x-axis\"\"\"\n",
    "    R = np.array([[1,0,0],[0,np.cos(theta),-np.sin(theta)],[0, np.sin(theta), np.cos(theta)]])\n",
    "    return np.array([np.dot(R,x) for x in vector])\n",
    "\n",
    "def y_rotation(vector,theta):\n",
    "    \"\"\"Rotates 3-D vector around y-axis\"\"\"\n",
    "    R = np.array([[np.cos(theta),0,np.sin(theta)],[0,1,0],[-np.sin(theta), 0, np.cos(theta)]])\n",
    "    return np.array([np.dot(R,x) for x in vector])\n",
    "\n",
    "def z_rotation(vector,theta):\n",
    "    \"\"\"Rotates 3-D vector around z-axis\"\"\"\n",
    "    R = np.array([[np.cos(theta), -np.sin(theta),0],[np.sin(theta), np.cos(theta),0],[0,0,1]])\n",
    "    return np.array([np.dot(R,x) for x in vector])\n",
    "\n",
    "\n",
    "# assume keypoints are headset relative 3D coordinates\n",
    "# return normalized keypoints, ie, each keypoint vector relative to its parent joint, normalized, with length also returned\n",
    "def keypoints_to_normalized(keypoints):\n",
    "    base_keypoints = keypoints.copy()\n",
    "\n",
    "    # keypoints[1] = base_keypoints[1] - base_keypoints[0] # headset fwd from headset\n",
    "    keypoints[2] = base_keypoints[2] - base_keypoints[8] # left controller from left elbow\n",
    "    keypoints[3] = base_keypoints[3] - base_keypoints[9] # right controller from right elbow\n",
    "    # keypoints[4] = base_keypoints[4] - base_keypoints[0] # head from headset\n",
    "    keypoints[5] = base_keypoints[5] - base_keypoints[4] # neck from head\n",
    "    keypoints[6] = base_keypoints[6] - base_keypoints[5] # left shoulder from neck\n",
    "    keypoints[7] = base_keypoints[7] - base_keypoints[5] # right shoulder from neck\n",
    "    keypoints[8] = base_keypoints[8] - base_keypoints[6] # left elbow from left shoulder\n",
    "    keypoints[9] = base_keypoints[9] - base_keypoints[7] # right elbow from right shoulder\n",
    "    keypoints[10] = base_keypoints[10] - base_keypoints[5] # left hip from neck\n",
    "    keypoints[11] = base_keypoints[11] - base_keypoints[5] # right hip from neck\n",
    "    keypoints[12] = base_keypoints[12] - base_keypoints[10] # left knee from left hip\n",
    "    keypoints[13] = base_keypoints[13] - base_keypoints[11] # right knee from right hip\n",
    "    keypoints[14] = base_keypoints[14] - base_keypoints[12] # left foot from left knee\n",
    "    keypoints[15] = base_keypoints[15] - base_keypoints[13] # right foot from right knee\n",
    "    keypoints[16] = base_keypoints[16] - base_keypoints[14] # left toes from left foot\n",
    "    keypoints[17] = base_keypoints[17] - base_keypoints[15] # right toes from right foot\n",
    "    # keypoints[18] = base_keypoints[18] - base_keypoints[0] # scale from headset\n",
    "\n",
    "    lengths = np.linalg.norm(keypoints, axis=1).reshape(-1,1)\n",
    "    # remove norm from keypoints\n",
    "    keypoints[1:] = keypoints[1:] / lengths[1:]\n",
    "    return np.concatenate((keypoints, lengths), axis=1)\n",
    "\n",
    "# assume input is 3d keypoints normalized to their parent joint with length included\n",
    "def normalized_to_keypoints(keypoints):\n",
    "    lengths = keypoints[:,-1].reshape(-1,1)\n",
    "    keypoints = keypoints[:,:-1] * lengths\n",
    "\n",
    "    # keypoints[1] = keypoints[1] + keypoints[0] # headset fwd from headset\n",
    "    # keypoints[4] = keypoints[4] + keypoints[0] # head from headset\n",
    "    keypoints[5] = keypoints[5] + keypoints[4] # neck from head\n",
    "    keypoints[6] = keypoints[6] + keypoints[5] # left shoulder from neck\n",
    "    keypoints[7] = keypoints[7] + keypoints[5] # right shoulder from neck\n",
    "    keypoints[8] = keypoints[8] + keypoints[6] # left elbow from left shoulder\n",
    "    keypoints[9] = keypoints[9] + keypoints[7] # right elbow from right shoulder\n",
    "    keypoints[2] = keypoints[2] + keypoints[8] # left controller from left elbow\n",
    "    keypoints[3] = keypoints[3] + keypoints[9] # right controller from right elbow\n",
    "    keypoints[10] = keypoints[10] + keypoints[6] # left hip from left shoulder\n",
    "    keypoints[11] = keypoints[11] + keypoints[7] # right hip from right shoulder\n",
    "    keypoints[12] = keypoints[12] + keypoints[10] # left knee from left hip\n",
    "    keypoints[13] = keypoints[13] + keypoints[11] # right knee from right hip\n",
    "    keypoints[14] = keypoints[14] + keypoints[12] # left foot from left knee\n",
    "    keypoints[15] = keypoints[15] + keypoints[13] # right foot from right knee\n",
    "    keypoints[16] = keypoints[16] + keypoints[14] # left toes from left foot\n",
    "    keypoints[17] = keypoints[17] + keypoints[15] # right toes from right foot\n",
    "    # keypoints[18] = keypoints[18] + keypoints[0] # scale from headset\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def process_keypoints(keypoints, camera_position, camera_direction, img_size=IMG_SIZE):\n",
    "    keypoints = pd.json_normalize(keypoints)\n",
    "\n",
    "    visibility_state = np.array(keypoints['state'].values)\n",
    "\n",
    "    if visibility_state.sum() < 13:\n",
    "        return None, None\n",
    "    \n",
    "    screenspace_coords = keypoints[['x','y']].values\n",
    "\n",
    "    if not (np.logical_and(screenspace_coords>6, screenspace_coords<(img_size-6)).sum() / len(screenspace_coords)) > 0.9:\n",
    "        return None, None\n",
    "    \n",
    "    global_coords = keypoints[['vx','vy','vz']].values\n",
    "\n",
    "    headset_relative_coords = global_coords - global_coords[0]\n",
    "    relative_camera_position = camera_position - global_coords[0]\n",
    "\n",
    "    xz_headset_fwd = np.array([headset_relative_coords[1][0], 0.0, headset_relative_coords[1][2]])\n",
    "    xz_headset_to_camera = np.array([relative_camera_position[0], 0.0, relative_camera_position[2]])\n",
    "    alignment_rotation = angle_between(xz_headset_fwd, xz_headset_to_camera)\n",
    "\n",
    "    camera_facing_coords = y_rotation(headset_relative_coords, alignment_rotation)\n",
    "\n",
    "    xz_headset_fwd = np.array([camera_facing_coords[1][0], 0.0, camera_facing_coords[1][2]])\n",
    "    new_angle = angle_between(xz_headset_fwd, xz_headset_to_camera)\n",
    "    if new_angle > 0.001:\n",
    "        camera_facing_coords = y_rotation(headset_relative_coords, -alignment_rotation)\n",
    "        # xz_headset_fwd = np.array([camera_facing_coords[1][0], 0.0, camera_facing_coords[1][2]])\n",
    "        # new_angle = angle_between(xz_headset_fwd, xz_headset_to_camera)\n",
    "        # print(new_angle)\n",
    "\n",
    "    # Normalize the keypoints\n",
    "    normalized_keypoints = keypoints_to_normalized(camera_facing_coords)\n",
    "\n",
    "    xz_headset_fwd = np.array([normalized_keypoints[1][0], 0.0, normalized_keypoints[1][2]])\n",
    "\n",
    "    output_keypoints = np.concatenate((normalized_keypoints, screenspace_coords, visibility_state.reshape(-1,1)), axis=1)\n",
    "    return output_keypoints, relative_camera_position\n",
    "\n",
    "\n",
    "def organize_and_process_captures(captures):\n",
    "    dfs = []\n",
    "    for capture in captures:\n",
    "        df = pd.json_normalize(pd.read_json(capture).values[:,1].tolist())[['id','sequence_id','step',\n",
    "                                                        'timestamp','filename','annotations']]\n",
    "        df.columns = ['row_id', 'seq_id','step','timestamp','rgb_filename','annotations']\n",
    "        keypoints = []\n",
    "        camera_positions = []\n",
    "        camera_directions = []\n",
    "        segmented_images = []\n",
    "        for annotation in df['annotations'].values:\n",
    "            annotation_values = annotation[2]['values']\n",
    "            if annotation_values:\n",
    "                annotation_values = annotation_values[0]\n",
    "\n",
    "                camera_position = np.array(list(annotation_values['camera_position'].values()))\n",
    "                camera_direction = np.array(list(annotation_values['camera_forward'].values()))\n",
    "\n",
    "                normalized_keypoints, camera_position = process_keypoints(annotation_values['keypoints'], camera_position, camera_direction)\n",
    "\n",
    "                keypoints.append(normalized_keypoints)\n",
    "                camera_positions.append(camera_position)\n",
    "                camera_directions.append(camera_direction)\n",
    "                segmented_images.append(annotation[1]['filename'])\n",
    "            else:\n",
    "                keypoints.append(None)\n",
    "                camera_positions.append(None)\n",
    "                camera_directions.append(None)\n",
    "                segmented_images.append(\"\")\n",
    "\n",
    "        df['keypoints'] = keypoints\n",
    "        df['camera_position'] = camera_positions\n",
    "        df['camera_direction'] = camera_directions\n",
    "        df['seg_filename'] = segmented_images\n",
    "\n",
    "        df['seg_filename'] = [os.path.join(all_datasets, selected_dataset, x) for x in df['seg_filename']]\n",
    "        df['rgb_filename'] = [os.path.join(all_datasets, selected_dataset, x) for x in df['rgb_filename']]\n",
    "        \n",
    "        dfs.append(df)\n",
    "    dfs = pd.concat(dfs)\n",
    "    dfs.drop('annotations',axis=1, inplace=True)\n",
    "    dfs.dropna(inplace=True, axis=0)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e601c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_captures = process_dataset(os.path.join(all_datasets, selected_dataset)) # , rgb_images, segmented_images\n",
    "df = organize_and_process_captures(data_captures)\n",
    "# use numpy to save the dataframe to a file\n",
    "np.save(os.path.join(all_datasets, selected_dataset, 'processed.npy'), df.to_numpy())\n",
    "# display the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1725c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "# df = pd.DataFrame(np.load(os.path.join(all_datasets, selected_dataset, 'processed.npy'), allow_pickle=True), \n",
    "#                       columns=['row_id', 'seq_id','step','timestamp','rgb_filename','keypoints','camera_position','camera_direction','seg_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c55ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:41:00.602572Z",
     "start_time": "2022-05-13T00:41:00.435429Z"
    }
   },
   "outputs": [],
   "source": [
    "# use plotly to create a function to print 3D keypoints to an interactive 3D plot\n",
    "def plot_keypoints(keypoints, camera_pos=None):\n",
    "    if camera_pos is not None:\n",
    "        keypoints_and_camera = np.concatenate((keypoints, np.array([camera_pos])), axis=0)\n",
    "        fig = px.scatter_3d(x=keypoints_and_camera[:,0], y=keypoints_and_camera[:,1], z=keypoints_and_camera[:,2], \n",
    "                            text=keypoint_labels[:len(keypoints)]+['camera'])\n",
    "    else:\n",
    "        fig = px.scatter_3d(x=keypoints[:,0], y=keypoints[:,1], z=keypoints[:,2], text=keypoint_labels[:len(keypoints)])\n",
    "    # set scale to be equal\n",
    "    fig.update_scenes(aspectmode='cube')\n",
    "    \n",
    "    # set plotly theme to dark\n",
    "    fig.update_layout(template='plotly_dark')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keypoints(normalized_to_keypoints(df['keypoints'].values[0][:,:4]), df['camera_position'].values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
