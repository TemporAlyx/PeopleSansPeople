{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbce91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.616161Z",
     "start_time": "2022-05-13T00:32:35.821479Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, sys, gc, json\n",
    "\n",
    "from scipy import stats\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9ecf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.631674Z",
     "start_time": "2022-05-13T00:32:36.617162Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_IMG_SIZE = 224 # size of images on disk\n",
    "dataset_loc = os.path.join(os.getcwd(), os.pardir, 'datasets')\n",
    "\n",
    "datasets = os.listdir(dataset_loc)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5818269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.647188Z",
     "start_time": "2022-05-13T00:32:36.632675Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_dataset = datasets[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c43e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:36.662701Z",
     "start_time": "2022-05-13T00:32:36.648689Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_dataset(loc, return_semantic=False):\n",
    "    data = os.listdir(loc)\n",
    "    capdata_loc = loc + [x for x in data if \"Dataset\" in x][0]\n",
    "    captures = [capdata_loc+'\\\\'+x for x in os.listdir(capdata_loc) if \"captures\" in x]\n",
    "    rgb_loc = loc + [x for x in data if \"RGB\" in x][0]\n",
    "    rgbs = [rgb_loc+'\\\\'+x for x in os.listdir(rgb_loc)]\n",
    "    if return_semantic:\n",
    "        semseg_loc = [x for x in data if \"Semantic\" in x][0]\n",
    "        semseg = [semseg_loc+'\\\\'+x for x in os.listdir(loc + semseg_loc)]\n",
    "        return captures, rgbs, semseg\n",
    "    return captures, rgbs\n",
    "\n",
    "def handle_captures(captures):\n",
    "    dfs = []\n",
    "    for capture in captures:\n",
    "        df = pd.json_normalize(pd.read_json(capture).values[:,1])[['id','sequence_id','step',\n",
    "                                                        'timestamp','filename','annotations']]\n",
    "#         print(df.columns)\n",
    "        df.columns = ['row_id', 'seq_id','step','timestamp','rgb_filename','annotations']\n",
    "        df['keypoints'] = [x[2]['values'][0]['keypoints'] if x[2]['values'] else None for \n",
    "                           x in df['annotations'].values]\n",
    "        df['seg_filename'] = [x[1]['filename'] for x in df['annotations'].values]\n",
    "        df['seg_filename'] = dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + df['seg_filename']\n",
    "        df['rgb_filename'] = dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + df['rgb_filename']\n",
    "        df = df.drop('annotations',axis=1)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)            \n",
    "\n",
    "def decomp_keypoints(dfs, img_size=512, return_semantic=False): \n",
    "    cdfv = dfs[['keypoints', 'rgb_filename', 'seg_filename']].values\n",
    "    Y = []\n",
    "    X = []\n",
    "    Z = []\n",
    "    c = 0\n",
    "    for vals in cdfv: # might be worth trying to multithread this\n",
    "        if vals[0] is not None:\n",
    "            df = pd.json_normalize(vals[0])\n",
    "            dxyval = df[['x','y']].values\n",
    "            if (df['state'].values.sum() > 11 # makes sure most keypoints are visible\n",
    "                and np.all(dxyval>6)          # checks whether keypoints are off the img edge\n",
    "                and np.all(dxyval<(img_size-6))):\n",
    "                dvxyz = df[['vx','vy','vz']].values\n",
    "                fdist = np.sqrt((dvxyz[0] - dvxyz[-1]) ** 2).sum()\n",
    "                \n",
    "                y = np.concatenate((\n",
    "                    (df[['x','y']].values / img_size)[:15],\n",
    "                    (df['state'].values / 2)[:15].reshape(-1,1),\n",
    "                    ((dvxyz - dvxyz[0]) / fdist)[:15]\n",
    "                    ), axis=-1)\n",
    "                \n",
    "                x = vals[1]\n",
    "                z = vals[2]\n",
    "                X.append(x); Y.append(y); Z.append(z)\n",
    "        c+=1\n",
    "        # if c%1000==0: #percFin(c, len(cdfv))\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Z = np.array(Z)\n",
    "    return X, Z, Y\n",
    "\n",
    "def filter_images(imgs): # could take several minutes for ~100000 images, \n",
    "    output = []          # theres probably a more efficient way to code this / multiprocessing\n",
    "    for filename in imgs:\n",
    "        fg = True\n",
    "        img = imread(filename) * 255\n",
    "#         print(img)\n",
    "        if img.std() < 11: # checks for images with low variance and low or high values\n",
    "            m = img.mean() # indicating either an entirely dark or whashed out image\n",
    "            if m < 11 or m > 220:\n",
    "                fg = False\n",
    "        output.append(fg)\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f254e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:37.546960Z",
     "start_time": "2022-05-13T00:32:37.539453Z"
    }
   },
   "outputs": [],
   "source": [
    "# checks if data preprocessing and image filtering has already been saved\n",
    "if os.path.isfile(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'keypoints.npy'):\n",
    "    keypoints = np.load(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'keypoints.npy')\n",
    "    rgbs = np.load(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'rgbs.npy')\n",
    "    segs = np.load(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'segs.npy')\n",
    "    print(keypoints.shape, rgbs.shape, segs.shape)\n",
    "else:\n",
    "    FX = process_dataset(dataset_loc + \"\\\\\" + selected_dataset + '\\\\', return_semantic=True)\n",
    "\n",
    "    dfs = handle_captures(FX[0])\n",
    "\n",
    "    rgbs, segs, keypoints = decomp_keypoints(dfs, img_size=DATA_IMG_SIZE, return_semantic=True)\n",
    "\n",
    "    # good_imgs = filter_images(rgbs)\n",
    "    # may take some time to process\n",
    "\n",
    "    # rgbs = rgbs[good_imgs]\n",
    "    # segs = segs[good_imgs]\n",
    "    # keypoints = keypoints[good_imgs]\n",
    "\n",
    "    np.save(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'keypoints.npy', keypoints)\n",
    "    np.save(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'rgbs.npy', rgbs)\n",
    "    np.save(dataset_loc + \"\\\\\" + selected_dataset + \"\\\\\" + 'segs.npy', segs)\n",
    "    print(keypoints.shape, rgbs.shape, segs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21496c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:43.782810Z",
     "start_time": "2022-05-13T00:32:39.084278Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import decomposition, ensemble, metrics, pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as backend\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras import regularizers, Model\n",
    "\n",
    "# import tensorflow_addons as tfa\n",
    "# import tensorflow_probability as tfp\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583967e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:32:45.303114Z",
     "start_time": "2022-05-13T00:32:45.286099Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 512 # image size in model (may need to be scaled down)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def decode_image(filename, label=None):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    img = tf.io.decode_png(bits, channels=3)\n",
    "    img = tf.image.resize_with_pad(img, IMG_SIZE, IMG_SIZE)\n",
    "#     img = tf.image.per_image_standardization(img)  # may be necessary depending on model\n",
    "    return img, label\n",
    "\n",
    "def tdata(length=len(keypoints) - 10000, offset=0, labels=keypoints, bs=BATCH_SIZE):\n",
    "    return (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((rgbs[offset:offset+length], labels[offset:offset+length]))\n",
    "        .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(bs)\n",
    "#         .cache()\n",
    "#         .shuffle(8)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "def vdata(length=10000, labels=keypoints, bs=BATCH_SIZE):\n",
    "    return (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((rgbs[-length:], labels[-length:]))\n",
    "    .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE) \n",
    "    .batch(bs)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training might look something like this\n",
    "\n",
    "# model.fit(tdata(36000, labels=Labels ,bs=256), \n",
    "#           validation_data=vdata(3600, labels=Labels, bs=256),\n",
    "#            epochs=100, verbose=1, callbacks=cbks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc84cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:39:33.375232Z",
     "start_time": "2022-05-13T00:39:33.372731Z"
    }
   },
   "outputs": [],
   "source": [
    "VX = rgbs[len(keypoints)-1000:]\n",
    "VY = keypoints[len(keypoints)-1000:].astype(np.float32)\n",
    "\n",
    "# VP = model.predict(vdata(1000, bs=256, img_size=256)).astype(np.float32)\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c55ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T00:41:00.602572Z",
     "start_time": "2022-05-13T00:41:00.435429Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(tf.io.decode_png(tf.io.read_file(VX[idx]), channels=3).numpy())\n",
    "# plt.scatter(VP[idx][:,0]*IMG_SIZE, VP[idx][:,1]*IMG_SIZE, s=(np.arange(1)*5)+3)\n",
    "# plt.subplot(1, 2, 2)\n",
    "plt.imshow(tf.io.decode_png(tf.io.read_file(VX[idx]), channels=3).numpy())\n",
    "plt.scatter(VY[idx][:,0]*IMG_SIZE, VY[idx][:,1]*IMG_SIZE, s=(np.arange(1)*5)+3)\n",
    "plt.show()\n",
    "idx += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f32cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195aaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd9a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83f4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465ef07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57785958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f06f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f2ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fb9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
